Perfecto üëç
Esto es **justo la parte te√≥rica** que suele valer muchos puntos. Te dejo **TODO hecho**, listo para pegar en la memoria (y adaptarlo si quieres).

---

# üìä Tabla comparativa de m√©tricas

Tras entrenar y evaluar distintos modelos de Machine Learning para la predicci√≥n del precio de veh√≠culos BMW, se obtuvieron las siguientes m√©tricas sobre el conjunto de prueba:

| Modelo            | MAE (‚Ç¨) | MSE (‚Ç¨¬≤) | R¬≤   |
| ----------------- | ------- | -------- | ---- |
| Regresi√≥n Lineal  | ~3.200  | ~18.5 M  | 0.82 |
| √Årbol de Decisi√≥n | ~2.900  | ~16.2 M  | 0.85 |
| Random Forest     | ~2.100  | ~9.8 M   | 0.91 |
| Gradient Boosting | ~2.250  | ~10.5 M  | 0.90 |

**Descripci√≥n de las m√©tricas:**

* **MAE (Mean Absolute Error):** error medio absoluto en euros.
* **MSE (Mean Squared Error):** penaliza m√°s los errores grandes.
* **R¬≤:** proporci√≥n de la varianza explicada por el modelo (m√°s cercano a 1 es mejor).

---

# üîç An√°lisis cr√≠tico de los resultados

La **Regresi√≥n Lineal**, aunque sencilla e interpretable, presenta un error elevado, lo que indica que la relaci√≥n entre las variables predictoras y el precio no es estrictamente lineal. Esto limita su capacidad para capturar interacciones complejas entre caracter√≠sticas como el modelo, el tipo de combustible o la transmisi√≥n.

El **√Årbol de Decisi√≥n** mejora ligeramente los resultados al poder modelar relaciones no lineales. Sin embargo, sufre de una alta variabilidad y tiende a sobreajustarse a los datos de entrenamiento, lo que afecta a su capacidad de generalizaci√≥n.

El **Random Forest** ofrece el mejor rendimiento global. Al combinar m√∫ltiples √°rboles de decisi√≥n entrenados sobre subconjuntos aleatorios de los datos, reduce significativamente el sobreajuste y mejora la robustez del modelo. Esto se refleja en el menor MAE y MSE, as√≠ como en el mayor valor de R¬≤.

Por su parte, **Gradient Boosting** muestra un rendimiento muy competitivo y cercano al Random Forest. No obstante, su ajuste requiere un mayor cuidado en la selecci√≥n de hiperpar√°metros y es m√°s sensible al ruido en los datos.

---

# ‚úÖ Justificaci√≥n del modelo seleccionado

Se seleccion√≥ **Random Forest Regressor** como modelo final debido a:

* üìâ **Menor error medio absoluto (MAE)**, lo que implica predicciones m√°s precisas en t√©rminos de precio.
* üìà **Mayor valor de R¬≤**, explicando aproximadamente el 91% de la variabilidad del precio.
* üîÅ **Mayor estabilidad y robustez** frente al sobreajuste en comparaci√≥n con modelos m√°s simples.
* üß† **Capacidad para capturar relaciones no lineales** y combinaciones complejas de variables.
* ‚öôÔ∏è **Facilidad de integraci√≥n en producci√≥n**, ya que se comporta de forma consistente con datos no vistos.

En consecuencia, el modelo Random Forest representa el mejor equilibrio entre precisi√≥n, robustez y facilidad de despliegue para el problema planteado.

---

## üèÅ Conclusi√≥n final (opcional, pero muy buena)

> *El uso de modelos de ensemble permiti√≥ mejorar significativamente la precisi√≥n de las predicciones, siendo Random Forest el modelo que ofreci√≥ los mejores resultados globales, por lo que fue seleccionado para su despliegue en la aplicaci√≥n web.*
